{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "810b0cc7-1f56-4e45-81ce-d69424865a7f",
   "metadata": {},
   "source": [
    "# Agentic Email Analyzer\n",
    "* read email from vector database\n",
    "* execute query and return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5bf842b3-e5ce-4183-ac94-dd2c6c4dfa13",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    WARNING CONTROL to display or ignore all warnings\n",
    "'''\n",
    "import warnings; warnings.simplefilter('ignore')     #switch betweeb 'default' and 'ignore'\n",
    "import traceback\n",
    "\n",
    "''' Set debug flag to view extended error messages; else set it to False to turn off debugging mode '''\n",
    "debug = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb52a779-e2e1-4733-8bb3-75f722026adb",
   "metadata": {},
   "source": [
    "## Instantiate classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43ee7dec-3615-4359-b92e-33f72c3f5b39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All functional VECTORDB-libraries in LOADER-package of ETL-module imported successfully!\n",
      "All functional CREW-libraries in EMAILPULSE-package of SHIPPING-module imported successfully!\n",
      "model Class initialization complete\n",
      "__propAttr__ Class initialization complete\n",
      "__propAttr__ Class initialization complete\n",
      "\n",
      "crewai agents and tasks class initialization and load complete!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import litellm\n",
    "os.environ['LITELLM_LOG'] = 'DEBUG' \n",
    "# litellm.set_verbose=True\n",
    "os.environ['CHROMA_TELEMETRY_ENABLED']='false'\n",
    "# os.environ[\"OLLAMA_BASE_URL\"] = \"http://192.168.2.200:5050\"\n",
    "litellm.api_base = \"http://192.168.2.200:5050\"\n",
    "\n",
    "proj_dir = os.path.abspath(os.pardir)\n",
    "sys.path.insert(1,proj_dir.split('mining/')[0])\n",
    "from dongcha.modules.etl.loader import vectorDB as db\n",
    "from mining.modules.shipping.emailPulse import crew as cr\n",
    "from mining.modules.shipping.emailPulse import agents as ag\n",
    "from mining.modules.shipping.emailPulse import tasks as ta\n",
    "from mining.modules.shipping.emailPulse.tools import rag as rag\n",
    "\n",
    "''' restart initiate classes '''\n",
    "if debug:\n",
    "    import importlib\n",
    "    db = importlib.reload(db)\n",
    "    cr = importlib.reload(cr)\n",
    "    ag = importlib.reload(ag)\n",
    "    ta = importlib.reload(ta)\n",
    "    rag = importlib.reload(rag)\n",
    "\n",
    "__desc__ = \"crewai agents and tasks\"\n",
    "clsCrew = cr.agentWorkLoads(desc=__desc__)\n",
    "print(\"\\n%s class initialization and load complete!\" % __desc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08bb18e1-502d-48b1-8be2-3f5394082128",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overriding of current TracerProvider is not allowed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mEmail insights and task analyst\u001b[00m\n",
      "\u001b[95m## Task:\u001b[00m \u001b[92mExecute the following steps in order: 1. Use the tool to retrieve the email content 2. Extract insights from the content to generate the key information:\n",
      "      a. short summary of the email thread context\n",
      "      b. pending and completed task list\n",
      "      c. weighting times between emails\n",
      "\u001b[00m\n",
      "Found collection NUWAN\n",
      "[Document(metadata={'chunk size': 200, 'overlap': 10}, page_content='The email content from 2025-01-01 to 2025-03-31 is as follows:'), Document(metadata={'chunk size': 200, 'overlap': 10}, page_content='Dominic\\n\\n2. Subject: Re: AI Agents\\nFrom: Dominic König <dominic@nursix.org>\\nDate: Tuesday, April'), Document(metadata={'chunk size': 200, 'overlap': 10}, page_content=\"But more than that - I'd like to discuss some EDXL-related questions with you, \\nif you can spare some time some time (drat...language :D).\\n\\nDominic\"), Document(metadata={'chunk size': 200, 'overlap': 10}, page_content='1. Subject: Re: AI Agents\\nFrom: Dominic König <dominic@nursix.org>\\nDate: Tuesday, April 1, 2025 12:58:49 CEST\\nBody: \\nSo, that is saying that AIs are necessary to multiply the capacity of')]\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mEmail insights and task analyst\u001b[00m\n",
      "\u001b[95m## Thought:\u001b[00m \u001b[92mTo execute the given task, I need to start by retrieving the email content using the available tool. This will provide me with the necessary information to extract insights and generate the required key information.\u001b[00m\n",
      "\u001b[95m## Using tool:\u001b[00m \u001b[92mEmail content retriever\u001b[00m\n",
      "\u001b[95m## Tool Input:\u001b[00m \u001b[92m\n",
      "\"{\\\"tool_input\\\": \\\"email content query\\\"}\"\u001b[00m\n",
      "\u001b[95m## Tool Output:\u001b[00m \u001b[92m\n",
      "The email content from 2025-01-01 to 2025-03-31 is as follows:\n",
      "Dominic\n",
      "\n",
      "2. Subject: Re: AI Agents\n",
      "From: Dominic König <dominic@nursix.org>\n",
      "Date: Tuesday, April\n",
      "But more than that - I'd like to discuss some EDXL-related questions with you, \n",
      "if you can spare some time some time (drat...language :D).\n",
      "\n",
      "Dominic\n",
      "1. Subject: Re: AI Agents\n",
      "From: Dominic König <dominic@nursix.org>\n",
      "Date: Tuesday, April 1, 2025 12:58:49 CEST\n",
      "Body: \n",
      "So, that is saying that AIs are necessary to multiply the capacity of\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mEmail insights and task analyst\u001b[00m\n",
      "\u001b[95m## Final Answer:\u001b[00m \u001b[92m\n",
      "Report: Email Thread Analysis\n",
      "\n",
      "I. Email Summary:\n",
      "The email thread context revolves around a discussion on AI Agents, specifically focusing on their necessity to multiply capacity. The conversation is between Dominic König and an unspecified recipient. The emails are dated April 1, 2025, and indicate a desire to discuss EDXL-related questions.\n",
      "\n",
      "II. Pending Tasks:\n",
      "1. Discuss EDXL-related questions with the recipient.\n",
      "2. Explore the role of AI Agents in multiplying capacity.\n",
      "\n",
      "III. Completed Tasks:\n",
      "None explicitly mentioned in the provided email content.\n",
      "\n",
      "IV. Estimated Response Times:\n",
      "Based on the provided email content, it is challenging to accurately estimate response times, as the timestamps for the recipient's emails are not included. However, the emails from Dominic König are dated on the same day, April 1, 2025, with one sent at 12:58:49 CEST. Without more information, it's difficult to provide a precise estimate of response times between emails.\n",
      "\n",
      "This report is based on the analysis of the provided email content and aims to extract key insights into the email thread context, pending and completed tasks, and estimated response times. Given the limited information, some aspects of the analysis are constrained.\u001b[00m\n",
      "\n",
      "\n",
      "Tasks Output ...:\n",
      "[TaskOutput(description='Execute the following steps in order: 1. Use the tool to retrieve the email content 2. Extract insights from the content to generate the key information:\\n      a. short summary of the email thread context\\n      b. pending and completed task list\\n      c. weighting times between emails\\n', name='content_analysis_task', expected_output='A structured report containing an email summary, pending tasks, \\n    completed tasks, and estimated response times.', summary='Execute the following steps in order: 1. Use the tool...', raw=\"Report: Email Thread Analysis\\n\\nI. Email Summary:\\nThe email thread context revolves around a discussion on AI Agents, specifically focusing on their necessity to multiply capacity. The conversation is between Dominic König and an unspecified recipient. The emails are dated April 1, 2025, and indicate a desire to discuss EDXL-related questions.\\n\\nII. Pending Tasks:\\n1. Discuss EDXL-related questions with the recipient.\\n2. Explore the role of AI Agents in multiplying capacity.\\n\\nIII. Completed Tasks:\\nNone explicitly mentioned in the provided email content.\\n\\nIV. Estimated Response Times:\\nBased on the provided email content, it is challenging to accurately estimate response times, as the timestamps for the recipient's emails are not included. However, the emails from Dominic König are dated on the same day, April 1, 2025, with one sent at 12:58:49 CEST. Without more information, it's difficult to provide a precise estimate of response times between emails.\\n\\nThis report is based on the analysis of the provided email content and aims to extract key insights into the email thread context, pending and completed tasks, and estimated response times. Given the limited information, some aspects of the analysis are constrained.\", pydantic=None, json_dict=None, agent='Email insights and task analyst\\n', output_format=<OutputFormat.RAW: 'raw'>)]\n",
      "\n",
      "Token Usage: total_tokens=1623 prompt_tokens=1072 completion_tokens=551 successful_requests=2\n"
     ]
    }
   ],
   "source": [
    "inputs={\"query\": \"Find the email content discussing task progress\"}\n",
    "crew_output = clsCrew._run(inputs=inputs)\n",
    "\n",
    "print(f\"Tasks Output ...:\\n{crew_output.tasks_output}\")\n",
    "print(f\"\\nToken Usage: {crew_output.token_usage}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "34db9464-53a9-47bb-9cbc-d320e8f3c9ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All functional VECTORDB-libraries in LOADER-package of ETL-module imported successfully!\n",
      "__propAttr__ Class initialization complete\n",
      "Found collection NUWAN\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<langchain_chroma.vectorstores.Chroma at 0x7f0d09e4c220>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "proj_dir = os.path.abspath(os.pardir)\n",
    "sys.path.insert(1,proj_dir.split('mining/')[0])\n",
    "from rezaware.modules.etl.loader import vectorDB as db\n",
    "\n",
    "if debug:\n",
    "    import importlib\n",
    "    db = importlib.reload(db)\n",
    "\n",
    "_db_type = 'chromadb'\n",
    "_db_root = os.path.join(\n",
    "    \"/home/nuwan/workloads/advantis/\",\n",
    "    \"wrangler/data/shipping/emailPulse/def_job123\")\n",
    "_db_name = 'email'\n",
    "_collection='nuwan'\n",
    "\n",
    "clsVDB = db.dataWorkLoads(\n",
    "    db_type=_db_type,\n",
    "    db_root=_db_root,\n",
    "    db_name=_db_name\n",
    ")\n",
    "coll_lst = [x.name for x in clsVDB.get_collections()]\n",
    "if _collection not in coll_lst:\n",
    "    print(\"No collection named %s must be one of %s\" \n",
    "          % (_collection.upper(), \n",
    "             \", \".join(coll_lst)))\n",
    "else:\n",
    "    print(\"Found collection %s\" % _collection.upper())\n",
    "\n",
    "retriever = clsVDB.read_vectors(\n",
    "    collection=_collection,   # the documents collection name\n",
    "    embedding_fn=None, #self.embedding_function,\n",
    "    )#.as_retriever()\n",
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d25751fd-488d-4f07-9baa-9f6abbb47c84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total documents in Chroma collection: 8\n"
     ]
    }
   ],
   "source": [
    "from chromadb import PersistentClient\n",
    "\n",
    "# Define the database path and collection name\n",
    "db_path = \"/home/nuwan/workspace/advantis/wrangler/data/shipping/emailPulse/def_job123/email\"\n",
    "collection_name = \"nuwan\"\n",
    "\n",
    "# Initialize PersistentClient\n",
    "client = PersistentClient(path=db_path)\n",
    "\n",
    "# Get the collection\n",
    "collection = client.get_collection(collection_name)\n",
    "\n",
    "# Count the documents\n",
    "document_count = collection.count()\n",
    "print(f\"Total documents in Chroma collection: {document_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "078f450c-2afc-407e-992f-932190cb5b3b",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Chroma' object has no attribute 'invoke'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtask progress\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m docs \u001b[38;5;241m=\u001b[39m \u001b[43mretriever\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m(query)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([doc\u001b[38;5;241m.\u001b[39mpage_content \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m docs]))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Chroma' object has no attribute 'invoke'"
     ]
    }
   ],
   "source": [
    "query = \"task progress\"\n",
    "docs = retriever.invoke(query)\n",
    "print(\"\\n\".join([doc.page_content for doc in docs]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "advantis-env",
   "language": "python",
   "name": "advantis-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
